---
title: "Practical Machine Learning project - predicting ways of performing barbell lifts"
author: "Olgierd Grodzki"
output: html_document
---

The goal of this project is to predict the manner in which a group of enthusiasts performed barbell lifts. The data was collected from accelerometers on the belt, forearm, arm, and dumbell of 6 participants. The target variable is the classe variable, which contains 5 different ways of performing the exercise correctly and incorrectly. This raport describes how the model is built, how the cross validation is used and what the expected out of sample error is. The built model is then used to predict 20 different test cases. 

# Preprocessing data

First, the data has to be loaded into R, and downloaded if it is not available. We also set the seed for the whole computation.

```{r cache=TRUE}
set.seed(12345)

if(!file.exists("pml-training.csv")){
    fileUrl <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
    download.file(fileUrl, destfile = "./pml-training.csv")
}

if(!file.exists("pml-testing.csv")){
    fileUrl <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
    download.file(fileUrl, destfile = "./pml-testing.csv")
}

training <- read.csv("pml-training.csv")
testing <- read.csv("pml-testing.csv")
```

The first part of preprocessing involves removing from the training and test sets columns containing variables we know we do not want to use as predictors. In this case, these variables are row number, user name and timestamp information.

```{r}
myTraining <- training[,c(-5:-1)]
myTesting <- testing[,c(-5:-1)]
```

Next we identify and remove near zero variance predictors from the training and test sets, we identify them in the training set and remove from both for consistency.

```{r cache=TRUE}
suppressMessages(library(caret))
nzv_result <- nearZeroVar(myTraining[,-155], saveMetrics=TRUE)
myTraining <- myTraining[,c(rownames(nzv_result[nzv_result$nzv == FALSE,]), "classe")]
myTesting <- myTesting[,c(rownames(nzv_result[nzv_result$nzv == FALSE,]), "problem_id")]
```

Next we remove rows containing NA values, because we will be using random forests.

```{r}
na_columns <- apply(myTraining, 2, function(x) any(is.na(x)))
myTraining <- myTraining[,!na_columns]
myTesting <- myTesting[,!na_columns]
```

# Building the model

We will build the random forest model using the train function from caret. Additionally, we will use 5-fold cross validation. (The training data is sampled because of resource constraints on my machine, ideally we would not sample the data, but rather use the entire training set)

```{r cache=TRUE}
cv_model <- train(classe ~ ., data = myTraining[sample(nrow(myTraining), 1000), ], method="rf",
                trControl = trainControl(method="cv", number=5),
                prox = TRUE, allowParallel = TRUE)
cv_model
```

We can also view the final model:

```{r}
model <- cv_model$finalModel
model
```

Concerning the out of sample error, since we are using a random forest, we have access to the out of bag error, which removes the need for a set aside test set and compute the out of sample error. The study of error estimates for bagged classifiers in Breiman [1996b], gives empirical evidence to show that the out-of-bag estimate is as accurate as using a test set of the same size as the training set.

# Predicting 20 different test cases

We can use the final model to predict 20 different test cases:

```{r}
predict(model, myTesting[,-54], type = "class")
```
